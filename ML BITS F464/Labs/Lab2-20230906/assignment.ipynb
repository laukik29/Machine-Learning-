{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploring the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with loading the training data from the csv into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_processed_splitted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the first 5 rows of this dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11553</td>\n",
       "      <td>1051</td>\n",
       "      <td>1159</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400</td>\n",
       "      <td>1052</td>\n",
       "      <td>1052</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>138500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8960</td>\n",
       "      <td>1008</td>\n",
       "      <td>1028</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11100</td>\n",
       "      <td>0</td>\n",
       "      <td>930</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>84900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15593</td>\n",
       "      <td>1304</td>\n",
       "      <td>2287</td>\n",
       "      <td>667</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>225000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  TotalBsmtSF  GrLivArea  GarageArea  PoolArea  OverallCond  \\\n",
       "0    11553         1051       1159         336         0            5   \n",
       "1     8400         1052       1052         288         0            5   \n",
       "2     8960         1008       1028         360         0            6   \n",
       "3    11100            0        930         308         0            7   \n",
       "4    15593         1304       2287         667         0            4   \n",
       "\n",
       "  Utilities  SalePrice  \n",
       "0    AllPub     158000  \n",
       "1    AllPub     138500  \n",
       "2    AllPub     115000  \n",
       "3    AllPub      84900  \n",
       "4    AllPub     225000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are all the features present? What is the range for each of the features along with their mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LotArea', 'TotalBsmtSF', 'GrLivArea', 'GarageArea', 'PoolArea',\n",
       "       'OverallCond', 'Utilities', 'SalePrice'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling and One-Hot Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must have noticed that some features `(such as Utilities)` are not continuous values.\n",
    "  \n",
    "These features contain values indicating different categories and must somehow be converted to numbers so that the computer can understand it. `(Computers only understand numbers and not strings)`\n",
    "  \n",
    "These features are called categorical features. We can represent these features as a `One-Hot Representation`\n",
    "  \n",
    "  \n",
    "You must have also noticed that all the other features, each are in a different scale. This can be detremental to the performance of our linear regression model and so we normalize them so that all of them are in the range $[0,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: When you are doing feature scaling, store the min/max which you will use to normalize somewhere. This is then to be used at testing time. Try to think why are doing this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AllPub' 'NoSeWa']\n",
      "      LotArea  TotalBsmtSF  GrLivArea  GarageArea  PoolArea  OverallCond  \\\n",
      "0       11553         1051       1159         336         0            5   \n",
      "1        8400         1052       1052         288         0            5   \n",
      "2        8960         1008       1028         360         0            6   \n",
      "3       11100            0        930         308         0            7   \n",
      "4       15593         1304       2287         667         0            4   \n",
      "...       ...          ...        ...         ...       ...          ...   \n",
      "1309     9020         1127       1165         490         0            7   \n",
      "1310    10793          780       1620         462         0            5   \n",
      "1311     8885          864        902         484         0            5   \n",
      "1312    11275          710       2978         564         0            7   \n",
      "1313    10206            0        944         528         0            3   \n",
      "\n",
      "      SalePrice  Utilities_AllPub  Utilities_NoSeWa  \n",
      "0        158000               1.0               0.0  \n",
      "1        138500               1.0               0.0  \n",
      "2        115000               1.0               0.0  \n",
      "3         84900               1.0               0.0  \n",
      "4        225000               1.0               0.0  \n",
      "...         ...               ...               ...  \n",
      "1309     174900               1.0               0.0  \n",
      "1310     152000               1.0               0.0  \n",
      "1311     131000               1.0               0.0  \n",
      "1312     242000               1.0               0.0  \n",
      "1313      82000               1.0               0.0  \n",
      "\n",
      "[1314 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Do the one-hot encoding here\n",
    "print(df['Utilities'].unique())\n",
    "df['Utilities'].value_counts()\n",
    "one_hot_encoded_data = pd.get_dummies(df, columns = ['Utilities'], dtype=float)\n",
    "print(one_hot_encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Utilities_AllPub</th>\n",
       "      <th>Utilities_NoSeWa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047924</td>\n",
       "      <td>0.172013</td>\n",
       "      <td>0.155426</td>\n",
       "      <td>0.236953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.170948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033186</td>\n",
       "      <td>0.172177</td>\n",
       "      <td>0.135268</td>\n",
       "      <td>0.203103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.143869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.164975</td>\n",
       "      <td>0.130746</td>\n",
       "      <td>0.253879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.111235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112283</td>\n",
       "      <td>0.217207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.069435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.066807</td>\n",
       "      <td>0.213421</td>\n",
       "      <td>0.367935</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.263991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  TotalBsmtSF  GrLivArea  GarageArea  PoolArea  OverallCond  \\\n",
       "0  0.047924     0.172013   0.155426    0.236953       0.0        0.500   \n",
       "1  0.033186     0.172177   0.135268    0.203103       0.0        0.500   \n",
       "2  0.035804     0.164975   0.130746    0.253879       0.0        0.625   \n",
       "3  0.045806     0.000000   0.112283    0.217207       0.0        0.750   \n",
       "4  0.066807     0.213421   0.367935    0.470381       0.0        0.375   \n",
       "\n",
       "   SalePrice  Utilities_AllPub  Utilities_NoSeWa  \n",
       "0   0.170948               1.0               0.0  \n",
       "1   0.143869               1.0               0.0  \n",
       "2   0.111235               1.0               0.0  \n",
       "3   0.069435               1.0               0.0  \n",
       "4   0.263991               1.0               0.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the feature scaling here\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(one_hot_encoded_data)\n",
    "scaled_df = pd.DataFrame(scaled_data,columns=one_hot_encoded_data.columns)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conversion to NumPy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so now that we have all preprocessed all the data, we need to convert it to numpy for our linear regression model\n",
    "  \n",
    "Assume that our dataset has a total of $N$ datapoints. Each datapoint having a total of $D$ features (after one-hot encoding), we want our numpy array to be of shape $(N, D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our task, we have to predict the `SalePrice`. We will need 2 numpy arrays $(X, Y)$. These represent the features and targets respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "new_df = one_hot_encoded_data[['SalePrice']].copy()\n",
    "new_df2 = one_hot_encoded_data[['LotArea','TotalBsmtSF','GrLivArea','PoolArea',\"OverallCond\",\"Utilities_AllPub\",\"Utilities_NoSeWa\"]].copy()\n",
    "X = new_df.to_numpy()\n",
    "Y = new_df2.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression formulation\n",
    "  \n",
    "We now have our data in the form we need. Let's try to create a linear model to get our initial (Really bad) prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say a single datapoint in our dataset consists of 3 features $(x_1, x_2, x_3)$, we can pose it as a linear equation as follows:\n",
    "$$ y = w_1x_1 + w_2x_2 + w_3x_3 + b $$\n",
    "Here we have to learn 4 parameters $(w_1, w_2, w_3, b)$\n",
    "  \n",
    "  \n",
    "Now how do we extend this to multiple datapoints?  \n",
    "  \n",
    "  \n",
    "Try to answer the following:\n",
    "- How many parameters will we have to learn in the cae of our dataset? (Don't forget the bias term)\n",
    "- Form a linear equation for our dataset. We need just a single matrix equation which correctly represents all the datapoints in our dataset\n",
    "- Implement the linear equation as an equation using NumPy arrays (Start by randomly initializing the weights from a standard normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have N data points and 3 features\n",
    "N = 1313  # Number of data points\n",
    "num_features = 9  # Number of features\n",
    "\n",
    "# Randomly initialize weights (3 weights per feature for each data point)\n",
    "weights = np.random.randn(N, num_features)\n",
    "\n",
    "# Randomly initialize bias (1 bias term for each data point)\n",
    "biases = np.random.randn(N, 1)\n",
    "\n",
    "# Generate random feature values for a single data point (for example)\n",
    "x_values = np.random.randn(num_features, 1)\n",
    "\n",
    "# Calculate predicted outputs for all data points\n",
    "predictions = np.dot(weights, x_values) + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does our model perform? Try comparing our predictions with the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Learning weights using gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these results are really horrible. We need to somehow update our weights so that it correclty represents our data. How do we do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must do the following:\n",
    "- We need some numerical indication for our performance, for this we define a Loss Function ( $\\mathscr{L}$ )\n",
    "- Find the gradients of the `Loss` with respect to the `Weights`\n",
    "- Update the weights in accordance to the gradients: $W = W - \\alpha\\nabla_W \\mathscr{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define the loss function:\n",
    "- We will use the MSE loss since it is a regression task. (Specify the assumptions we make while doing so as taught in the class).\n",
    "- Implement this loss as a function. (Use numpy as much as possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mse_loss_fn(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error (MSE) loss.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Array of true target values.\n",
    "    - y_pred: Array of predicted values.\n",
    "\n",
    "    Returns:\n",
    "    - mse_loss: MSE loss value.\n",
    "    \"\"\"\n",
    "    # Calculate the squared differences\n",
    "    squared_diff = (y_true - y_pred) ** 2\n",
    "    \n",
    "    # Calculate the mean of squared differences\n",
    "    mse_loss = np.mean(squared_diff)\n",
    "    \n",
    "    return mse_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the gradients of the loss with respect to the weights (and biases). First write the equations down on a piece of paper, then proceed to implement it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(y_true, y_pred, W, b, X):\n",
    "    \"\"\"\n",
    "    Calculates the gradients for the MSE loss function with respect to the weights (and bias)\n",
    "\n",
    "    Args:\n",
    "        y_true: The true values of the target variable\n",
    "        y_pred: The predicted values of the target variable using our model (W*X + b)\n",
    "        W: The weights of the model\n",
    "        b: The bias of the model\n",
    "        X: The input features\n",
    "\n",
    "    Returns:\n",
    "        dW: The gradients of the loss function with respect to the weights\n",
    "        db: The gradients of the loss function with respect to the bias\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(y_true)  # Number of data points\n",
    "    \n",
    "    # Calculate the gradient with respect to the weights\n",
    "    dW = (-2/N) * np.dot(X.T, (y_true - y_pred))\n",
    "    \n",
    "    # Calculate the gradient with respect to the bias\n",
    "    db = (-2/N) * np.sum(y_true - y_pred)\n",
    "    \n",
    "    return dW, db\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights using the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(weights, bias, gradients_weights, gradients_bias, lr):\n",
    "    \"\"\"\n",
    "    Updates the weights (and bias) using the gradients and the learning rate\n",
    "\n",
    "    Args:\n",
    "        weights: The current weights of the model\n",
    "        bias: The current bias of the model\n",
    "        gradients_weights: The gradients of the loss function with respect to the weights\n",
    "        gradients_bias: The gradients of the loss function with respect to the bias\n",
    "        lr: The learning rate\n",
    "\n",
    "    Returns:\n",
    "        weights_new: The updated weights of the model\n",
    "        bias_new: The updated bias of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Update the weights using the gradients and learning rate\n",
    "    weights_new = weights - lr * gradients_weights\n",
    "    \n",
    "    # Update the bias using the gradients and learning rate\n",
    "    bias_new = bias - lr * gradients_bias\n",
    "    \n",
    "    return weights_new, bias_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all these together to find the loss value, its gradient and finally updating the weights in a loop. Feel free to play around with different learning rates and epochs\n",
    "  \n",
    "> NOTE: The code in comments are just meant to be used as a guide. You will have to do changes based on your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (9,1) and (1313,9) not aligned: 1 (dim 1) != 1313 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m      7\u001b[0m     \u001b[39m# Forward pass: Calculate predictions\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(x_values, weights) \u001b[39m+\u001b[39m biases\n\u001b[0;32m     10\u001b[0m     \u001b[39m# Calculate the Mean Squared Error (MSE) loss\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean((Y \u001b[39m-\u001b[39m y_pred)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (9,1) and (1313,9) not aligned: 1 (dim 1) != 1313 (dim 0)"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 2e-2\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Forward pass: Calculate predictions\n",
    "    y_pred = np.dot(x_values, weights) + biases\n",
    "    \n",
    "    # Calculate the Mean Squared Error (MSE) loss\n",
    "    loss = np.mean((Y - y_pred)**2)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Compute the gradients of the loss with respect to weights and bias\n",
    "    gradient_weights = (-2/len(Y)) * np.dot(X.T, (Y - y_pred))\n",
    "    gradient_bias = (-2/len(Y)) * np.sum(Y - y_pred)\n",
    "    \n",
    "    # Update weights and bias using gradient descent\n",
    "    W -= LEARNING_RATE * gradient_weights\n",
    "    b -= LEARNING_RATE * gradient_bias\n",
    "\n",
    "    # Print the loss at each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}: Loss = {loss:.4f}\")\n",
    "\n",
    "# After training, the weights (W) and bias (b) have been updated.\n",
    "print(\"Trained Weights:\", W)\n",
    "print(\"Trained Bias:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use matplotlib to plot the loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NUM_EPOCHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39mrange\u001b[39m(NUM_EPOCHS), losses)\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NUM_EPOCHS' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(range(NUM_EPOCHS), losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing with test data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and apply all the preprocessing steps used in the training data for the testing data as well. Remember to use the **SAME** min/max values which you used for the training set and not recalculate them from the test set. Also mention why we are doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the weights learnt above, predict the values in the test dataset. Also answer the following questions:\n",
    "- Are the predictions good?\n",
    "- What is the MSE loss for the testset\n",
    "- Is the MSE loss for testing greater or lower than training\n",
    "- Why is this the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
